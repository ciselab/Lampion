This txt contains infos what to remove from the datapoints in the original test-set as provided by codeberts team.
I highly recommend that you use the cleaned dataset provided by me, as this list is maybe not complete. 
If you remove a datapoint, remove the whole json-line. For my experiments  I did not attempt to "fix" any datapoints, I only removed them.

Remove all Entries with the following shas/repos: 

    - ad494dc8bce2345567de7689d42291d4b30fbd51 (rupertlssmith/lojix)
    - D19e9fcc636462c0f0ae1b7eca4acafae48de21b
    - wmixvideo/nfe

Remove the following items: 

GeoPackageCursorFactory RegisterTable
GeoPackageFactory getManager
GeoPackageImpl integrityCheck
GeoPackageManagerImp 
	addExternalDatabases
	addInternalDatabases
	createAndCloseGeoPackage
	deleteMissingDatabases
	getGeoPackageMetadata
	getGeoPackageMetadataAtExternalPackage
	importGeoPackage
	isDatabaseHeadervalid
	isValid
	validateDatabase
	validateDatabaseAndClose
	validateDatabaseAndCloseOnError
    validateDatabaseHeader
Fincatto/documentofiscal/mdfe3 
fincatto/documentofiscal/cte300


I had a script to iterate over single files and find "the bad guys" - if you really want to debug e.g. the training set in a similar way, 
reach out to me. 
I did not publish it as it was not ... super nice and not required after finding the 40 bad entries.